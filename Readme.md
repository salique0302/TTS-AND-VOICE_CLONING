# Voice Cloning TTS with Mel Spectrogram Visualization ğŸ™ï¸

<div align="center">

A text-to-speech application using XTTS v2 with real-time mel spectrogram visualization and voice cloning capabilities.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.68.0+-00a393.svg)](https://fastapi.tiangolo.com/)
[![TTS](https://img.shields.io/badge/TTS-v2.0+-red.svg)](https://github.com/coqui-ai/TTS)

</div>

---

## âœ¨ Features

- ğŸ—£ï¸ **Text to Speech Synthesis**: Using Coqui TTS XTTS v2 model
- ğŸ‘¥ **Voice Cloning**: Support for custom voice through .wav file upload
- ğŸ“Š **Mel Spectrogram Generation**: Real-time visualization of speech synthesis
- ğŸŒ **Multi-Language Support**:
  - ğŸ‡ºğŸ‡¸ English
  - ğŸ‡ªğŸ‡¸ Spanish
  - ğŸ‡«ğŸ‡· French
  - ğŸ‡©ğŸ‡ª German
  - ğŸ‡®ğŸ‡¹ Italian
- ğŸ’» **Interactive Web Interface**: Modern UI with dark/light theme
- ğŸŒŠ **Real-time Audio Visualization**: Waveform animation during playback

## ğŸš€ Installation

1. Clone the repository:
```bash
git clone <repository-url>
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Run the application:
```bash
uvicorn app:app --reload
```

## ğŸ“¦ Requirements

```plaintext
fastapi
uvicorn
python-multipart
torch
torchaudio
TTS
numpy
librosa
matplotlib
```

## ğŸ“ Project Structure

```plaintext
project/
â”œâ”€â”€ app.py              # FastAPI application
â”œâ”€â”€ mel_generator.py    # Mel spectrogram generation
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html     # Web interface
â”œâ”€â”€ generated_audio/    # Output directory
â””â”€â”€ dataset/
    â””â”€â”€ wavs/          # Default speaker samples
```

## ğŸ“ Usage

1. Access the web interface at `http://localhost:8000`
2. Enter text in the input field
3. Select desired language
4. Optionally upload a .wav file for voice cloning
5. Click "Generate Speech"
6. View the generated mel spectrogram and play the synthesized audio

## ğŸ”§ Technical Details

### Backend (app.py)
- ğŸš€ FastAPI framework
- ğŸ§  XTTS v2 model for speech synthesis
- ğŸ—ï¸ DeepLab architecture implementation
- âš¡ Real-time mel spectrogram generation

### Frontend (index.html)
- ğŸ“± Responsive design using TailwindCSS
- ğŸŒ“ Dark/Light theme toggle
- ğŸµ Audio visualization
- ğŸ“¤ File upload handling
- âš¡ Asynchronous API communication

### Mel Spectrogram Generation
| Parameter | Value |
|-----------|-------|
| Sample rate | 22050 Hz |
| FFT size | 1024 |
| Hop length | 256 |
| Mel bands | 80 |

## ğŸ”Œ API Endpoints

### POST `/generate-speech`
Generates speech from text with optional voice cloning.

#### Parameters:
| Name | Type | Required | Description |
|------|------|----------|-------------|
| `text` | string | Yes | Input text |
| `language` | string | No | Target language (default: "en") |
| `speaker_wav` | file | No | Voice sample file (.wav) |

#### Response:
- Audio file (.wav)
- Mel spectrogram visualization (.png)

### GET `/health`
Health check endpoint returning model and system status.

## ğŸ› ï¸ Development

The application leverages:
- ğŸ”¥ PyTorch for deep learning
- ğŸµ TorchAudio for audio processing
- ğŸ“Š LibROSA for mel spectrogram generation
- ğŸ“ˆ Matplotlib for visualization

## ğŸŒ Browser Support

- âœ… Chrome (recommended)
- âœ… Firefox
- âœ… Safari
- âœ… Edge

## âš ï¸ Known Limitations

- Requires a default speaker file at `dataset/wavs/1.wav`
- Audio files must be in WAV format
- Processing time varies based on text length

## ğŸ” Error Handling

- ğŸ“ File not found errors for missing speaker files
- ğŸµ Audio processing errors
- ğŸ¤– Model inference errors
- âœï¸ Invalid input validation

---

<div align="center">
  <p><strong>A sophisticated text-to-speech system with voice cloning capabilities</strong></p>
  <p>Made with â¤ï¸ using FastAPI and PyTorch</p>
</div>

