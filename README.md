# TTS-AND-VOICE_CLONINGâ–¶ï¸ ğŸ—£ï¸â€¢áŠáŠ||áŠ|á‹||||á‹â€Œâ€Œâ€Œâ€Œâ€ŒáŠ|â€¢ 0:10
# Voice Cloning TTS with Mel Spectrogram Visualization ğŸ§

<div align="center">

A text-to-speech application using XTTS v2 with real-time mel spectrogram visualization and voice cloning capabilities.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.68.0+-00a393.svg)](https://fastapi.tiangolo.com/)
[![TTS](https://img.shields.io/badge/TTS-v2.0+-red.svg)](https://github.com/coqui-ai/TTS)

</div>

---

## âœ¨ Features

- ğŸ—£ï¸ **Text to Speech Synthesis**: Powered by Coqui TTS XTTS v2 model
- ğŸ‘¥ **Voice Cloning**: Supports custom voice cloning using .wav files
- ğŸ“Š **Mel Spectrogram Generation**: Visualizes synthesized speech in real time
- ğŸŒ **Multi-Language Support**:
  - ğŸ‡ºğŸ‡¸ English
  - ğŸ‡ªğŸ‡¸ Spanish
  - ğŸ‡«ğŸ‡· French
  - ğŸ‡©ğŸ‡ª German
  - ğŸ‡®ğŸ‡¹ Italian
- ğŸ’» **Interactive Web Interface**: Modern UI with dark/light theme
- ğŸŒŠ **Real-time Audio Visualization**: Waveform animation during playback

## ğŸš€ Installation

1. Clone the repository:
```bash
git clone <your-repository-url>
cd <repository-name>
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Run the application:
```bash
uvicorn app:app --reload
```

## ğŸ“¦ Requirements

```plaintext
fastapi
uvicorn
python-multipart
torch
torchaudio
TTS
numpy
librosa
matplotlib
```

## ğŸ’ï¸â€â™‚ï¸ Project Structure

```plaintext
project/
â”œâ”€â”€ app.py              # FastAPI application
â”œâ”€â”€ mel_generator.py    # Mel spectrogram generation
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html      # Web interface
â”œâ”€â”€ generated_audio/    # Output directory
â””â”€â”€ dataset/
    â””â”€â”€ wavs/          # Default speaker samples
```

## ğŸ“ Usage

1. Open `http://localhost:8000` in your browser.
2. Enter text in the input field.
3. Select the desired language.
4. (Optional) Upload a .wav file for voice cloning.
5. Click "Generate Speech."
6. View the generated mel spectrogram and play the synthesized audio.

## ğŸ› ï¸ Technical Details

### Backend (app.py)
- âš¡ FastAPI framework
- ğŸ§  XTTS v2 model for speech synthesis
- ğŸ› ï¸ DeepLab architecture implementation
- ğŸ”¦ Real-time mel spectrogram generation

### Frontend (index.html)
- ğŸ“± Responsive design using TailwindCSS
- ğŸŒ„ Dark/Light theme toggle
- ğŸµ Audio visualization
- ğŸ‘ File upload handling
- âš¡ Asynchronous API communication

### Mel Spectrogram Parameters
| Parameter | Value |
|-----------|-------|
| Sample rate | 22050 Hz |
| FFT size | 1024 |
| Hop length | 256 |
| Mel bands | 80 |

## ğŸ”€ API Endpoints

### POST `/generate-speech`
Generates speech from text with optional voice cloning.

#### Parameters:
| Name | Type | Required | Description |
|------|------|----------|-------------|
| `text` | string | Yes | Input text |
| `language` | string | No | Target language (default: "en") |
| `speaker_wav` | file | No | Voice sample file (.wav) |

#### Response:
- Generated audio file (.wav)
- Mel spectrogram visualization (.png)

### GET `/health`
Health check endpoint returning model and system status.

## ğŸ› ï¸ Development

- ğŸ”¥ PyTorch for deep learning
- ğŸµ TorchAudio for audio processing
- ğŸ“Š LibROSA for mel spectrogram generation
- ğŸ“Š Matplotlib for visualization

## ğŸŒ Browser Support

- âœ… Chrome (recommended)
- âœ… Firefox
- âœ… Safari
- âœ… Edge

## âš  Known Limitations

- Requires a default speaker file at `dataset/wavs/1.wav`
- Supports only WAV format for voice cloning
- Processing time depends on text length

## ğŸ” Error Handling

- ğŸ’¾ File not found errors for missing speaker files
- ğŸµ Audio processing errors
- ğŸ¤– Model inference errors
- âœï¸ Input validation errors

---

<div align="center">
  <p><strong>A powerful text-to-speech system with voice cloning capabilities</strong></p>
  <p>Made with â¤ï¸ using FastAPI and PyTorch</p>
</div>

